## See Vector helm documentation to learn more:
## https://vector.dev/docs/setup/installation/package-managers/helm/

# nameOverride -- Override name of app
fullnameOverride: vector

## Create a Secret resource for Vector to use
secrets:
  # secrets.generic -- Each Key/Value will be added to the Secret's data key, each value should be raw and NOT base64 encoded
  ## Any secrets can be provided here, it's commonly used for credentials and other access related values.
  ## NOTE: Don't commit unencrypted secrets to git!
  generic:
    datadog_api_key: "REPLACE_ME"

## Configure a HorizontalPodAutoscaler for Vector
autoscaling:
  enabled: true
  minReplicas: 2
  ## The provided HAProxy config is limited to 10 backends
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80

podDisruptionBudget:
  enabled: true
  minAvailable: 1

# env -- Set environment variables in Vector containers
## The examples below leverage examples from secrets.generic and assume no name overrides with a Release name of "vector"
env:
  - name: DATADOG_API_KEY
    valueFrom:
      secretKeyRef:
        name: vector
        key: datadog_api_key
  - name: VECTOR_LOG_FORMAT
    value: json

# envFrom -- Define environment variables from Secrets or ConfigMaps
envFrom:
  - secretRef:
      name: vector

# resources -- Set Vector resource requests and limits.
resources:
  ## Required for HPA to function
  requests:
    cpu: 1000m
    memory: 512Mi
  # limits:
  #   cpu: 200m
  #   memory: 256Mi

# affinity -- Allow Vector to schedule using affinity rules
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity:
  ## Scale across different AZs by default.
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - vector
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - Aggregator
          topologyKey: topology.kubernetes.io/zone

# customConfig -- Override Vector's default configs, if used **all** options need to be specified
## This section supports using helm templates to populate dynamic values
## Ref: https://vector.dev/docs/reference/configuration/
customConfig:
  data_dir: /vector-data-dir
  api:
    enabled: true
    address: 0.0.0.0:8686
    playground: false
  sources:
    datadog_agent:
      address: 0.0.0.0:8282
      type: datadog_agent
      multiple_outputs: true
    internal_metrics:
      type: internal_metrics
  transforms:
    remap_logs:
      type: remap
      inputs:
        - datadog_agent.logs
      source: |
        # Parse the received .ddtags field so we can more easily access the contained tags
        .ddtags = parse_key_value!(.ddtags, key_value_delimiter: ":", field_delimiter: ",")
        .ddtags.sender = "vector"
        .ddtags.vector_aggregator = get_hostname!()
        # Re-encode Datadog tags as a string for the `datadog_logs` sink
        .ddtags = encode_key_value(.ddtags, key_value_delimiter: ":", field_delimiter: ",")

        # Datadog Agents pass a "status" field that is stripped when ingested
        del(.status)
  sinks:
    datadog_logs:
      type: datadog_logs
      inputs:
        - remap_logs
      default_api_key: ${DATADOG_API_KEY}
      compression: gzip
    datadog_metrics:
      type: datadog_metrics
      inputs:
        - datadog_agent.metrics
        - internal_metrics
      default_api_key: ${DATADOG_API_KEY}
    # TODO: soon!
    # datadog_traces:
    #   type: datadog_traces

# livenessProbe -- Override default liveness probe settings, if customConfig is used requires customConfig.api.enabled true
## Requires Vector's API to be enabled
livenessProbe:
  httpGet:
    path: /health
    port: api

# readinessProbe -- Override default readiness probe settings, if customConfig is used requires customConfig.api.enabled true
## Requires Vector's API to be enabled
readinessProbe:
  httpGet:
    path: /health
    port: api

## Optional built-in HAProxy load balancer
haproxy:
  # haproxy.enabled -- If true, create a HAProxy load balancer
  enabled: true

  # haproxy.customConfig -- Override HAProxy's default configs, if used **all** options need to be specified.
  # This parameter supports using Helm templates to insert values dynamically
  ## By default this chart will parse Vector's configuration from customConfig to generate HAProxy's config, this generated config
  ## can be overwritten with haproxy.customConfig
  customConfig: |
    global
      log stdout format raw local0
      maxconn 4096
      stats socket /tmp/haproxy
      hard-stop-after {{ .Values.haproxy.terminationGracePeriodSeconds }}s

    defaults
      log     global
      option  dontlognull
      retries 3
      option  redispatch
      option  allbackups
      timeout client 5s
      timeout server 5s
      timeout connect 5s

    resolvers coredns
      nameserver dns1 kube-dns.kube-system.svc.cluster.local:53
      resolve_retries 3
      timeout resolve 2s
      timeout retry 1s
      accepted_payload_size 8192
      hold valid 10s
      hold obsolete 60s

    frontend stats
      mode http
      bind :::1024
      option httplog
      http-request use-service prometheus-exporter if { path /metrics }

    frontend datadog-agent
      mode http
      bind :::8282
      option httplog
      default_backend datadog-agent

    backend datadog-agent
      mode http
      balance roundrobin
      option tcp-check
      server-template srv 10 _datadog-agent._tcp.{{ include "vector.fullname" $ }}-headless.{{ $.Release.Namespace }}.svc.cluster.local resolvers coredns check
